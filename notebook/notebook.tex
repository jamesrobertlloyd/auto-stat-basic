\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}

\usepackage{listings}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{amssymb,amsmath}
%\usepackage{graphicx}
\usepackage{preamble}
%\usepackage{natbib}
%%%% REMEMBER ME!
%\usepackage[draft]{hyperref}
\usepackage{hyperref}
\usepackage{color}
\usepackage{url}
%\usepackage{wasysym}
%\usepackage{subfigure}
%\usepackage{tabularx}
\usepackage{booktabs}
%\usepackage{bm}
%\newcommand{\theHalgorithm}{\arabic{algorithm}}
\definecolor{mydarkblue}{rgb}{0,0.08,0.45}
\hypersetup{ %
    pdftitle={},
    pdfauthor={},
    pdfsubject={},
    pdfkeywords={},
    pdfborder=0 0 0,
    pdfpagemode=UseNone,
    colorlinks=true,
    linkcolor=mydarkblue,
    citecolor=mydarkblue,
    filecolor=mydarkblue,
    urlcolor=mydarkblue,
    pdfview=FitH}

\setlength{\marginparwidth}{0.6in}
\input{include/commenting.tex}

%% For submission, make all render blank.
%\renewcommand{\LATER}[1]{}
%\renewcommand{\fLATER}[1]{}
%\renewcommand{\TBD}[1]{}
%\renewcommand{\fTBD}[1]{}
%\renewcommand{\PROBLEM}[1]{}
%\renewcommand{\fPROBLEM}[1]{}
%\renewcommand{\NA}[1]{#1}  %% Note, NA's pass through!

% Definitions of handy macros can go here

% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}

%\jmlrheading{Volume}{Year}{Pages}{Submitted}{Published}{James Robert Lloyd}

% Short headings should be running head and authors last names

\ShortHeadings{Auto stat basic architecture}{Lloyd et alia}
\firstpageno{1}

\begin{document}

\lstset{language=Lisp,basicstyle=\ttfamily\footnotesize} 

\title{Designing an API for the automatic statistician}

\author{\name James Robert Lloyd \email jrl44@cam.ac.uk \\
       \addr 
       Machine Learning Group \\
       Department of Engineering\\
       University of Cambridge\\
       \AND
       \name Others\dots}

\editor{Not applicable}

\maketitle

\begin{abstract}
A discussion of potential software architectures for the automatic statistician.
\end{abstract}

%\begin{keywords}
%  Gaussian processes
%\end{keywords}

\section{Introduction}

Zoubin is hoping for many students to start working on the automatic statistician project.
Current software is mostly unusable by the public.
Let's try to change that!

The plan is to design a modular system that could be called the automatic statistician.
New students can then contribute new code that satisifies certain protocols to enhance the automatic statistician.

\section{Simplifying assumptions}

We will initially make many simplifying assumptions with a view to relaxing them as we expand the basic architecture:

\begin{itemize}
  \item Data assumed to be an exchangeable sequence of vectors
  \item Only building conditional models of a single output
  \item Minimal user interaction
  \item The type of each variable (\eg binary, real valued, ordinal\dots) is known
  \item \dots
\end{itemize}

\section{Examples of desired functionality}

This describes tasks the system should be able to perform.
Some are within the scope of the current simplifying assumptions, others will require additional interfaces / messaging protocols.

\subsection{Cross validated model selection}

The data is split into folds.
For each train / validation split the training data is used to build a number of models.
The predictions of these models are then compared to the validation data and scored.
The model with the best score is then trained on the full data and returned as the selected model.

While cross validated model selection trains one model for each fold (and then another for the full data), the models trained on each fold do not need to be returned to the user.
A potential flow could be
\begin{itemize}
  \item Manager creates data set object, cross validation folds object and scoring object
  \item Manager creates several expert objects which are given access to the data, cross validation object and scoring object
  \item Experts train models (on full data) and calculate cross validated performance and store this in local knowledge bases
  \item Experts return models and cross validation performance (a tuple of model, data set, cross validation object, method of scoring, score)
  \item Manager collates facts about cross validated performance and selects a model on the basis of these facts
\end{itemize}

\subsection{Bayesian model selection}

\subsection{Bayesian model averaging}

\subsection{Bayesian optimisation of model selection}

\subsection{Cross vaidated ensemble construction}

\section{Other desiderata}

\begin{itemize}
  \item Concurrency
  \item Language independence
  \item System independence
  \item Scalability
  \item \dots
\end{itemize}

\section{Definition of architecture}

Concurrency suggests a framework involving actors passing messages to each other.
The messages should be language independent, suggesting perhaps an XML syntax of messages?

\subsection{Overview}

\subsection{Minimum messages}

Things like start, pause, clear, load.

\subsection{Optional messages}

Things like returning models or cross validated errors.

\subsection{Future messages}

Types of message that might be useful in future versions of the system. 

\newpage

%\appendix
%\section*{Appendix A.}
%Appendix

\vskip 0.2in
\bibliography{library}

\end{document}
